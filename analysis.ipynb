{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.stats import pearsonr\n",
    "# from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from nltk import cluster\n",
    "\n",
    "\n",
    "from nltk.cluster import cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "# To prevent page crashes\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_names = [\n",
    "    '1800-w.npy',\n",
    "    '1810-w.npy',\n",
    "    '1820-w.npy',\n",
    "    '1830-w.npy',\n",
    "    '1840-w.npy',\n",
    "    '1850-w.npy',\n",
    "    '1860-w.npy',\n",
    "    '1870-w.npy',\n",
    "    '1880-w.npy',\n",
    "    '1890-w.npy',\n",
    "    '1900-w.npy',\n",
    "    '1910-w.npy',\n",
    "    '1920-w.npy',\n",
    "    '1930-w.npy',\n",
    "    '1940-w.npy',\n",
    "    '1950-w.npy',\n",
    "    '1960-w.npy',\n",
    "    '1970-w.npy',\n",
    "    '1980-w.npy',\n",
    "    '1990-w.npy'\n",
    "]\n",
    "\n",
    "v_names = [\n",
    "    '1800-vocab.pkl',\n",
    "    '1810-vocab.pkl',\n",
    "    '1820-vocab.pkl',\n",
    "    '1830-vocab.pkl',\n",
    "    '1840-vocab.pkl',\n",
    "    '1850-vocab.pkl',\n",
    "    '1860-vocab.pkl',\n",
    "    '1870-vocab.pkl',\n",
    "    '1880-vocab.pkl',\n",
    "    '1890-vocab.pkl',\n",
    "    '1900-vocab.pkl',\n",
    "    '1910-vocab.pkl',\n",
    "    '1920-vocab.pkl',\n",
    "    '1930-vocab.pkl',\n",
    "    '1940-vocab.pkl',\n",
    "    '1950-vocab.pkl',\n",
    "    '1960-vocab.pkl',\n",
    "    '1970-vocab.pkl',\n",
    "    '1980-vocab.pkl',\n",
    "    '1990-vocab.pkl'\n",
    "]\n",
    "\n",
    "w_keys = [\n",
    "    '1800',\n",
    "    '1810',\n",
    "    '1820',\n",
    "    '1830',\n",
    "    '1840',\n",
    "    '1850',\n",
    "    '1860',\n",
    "    '1870',\n",
    "    '1880',\n",
    "    '1890',\n",
    "    '1900',\n",
    "    '1910',\n",
    "    '1920',\n",
    "    '1930',\n",
    "    '1940',\n",
    "    '1950',\n",
    "    '1960',\n",
    "    '1970',\n",
    "    '1980',\n",
    "    '1990'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'palace'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonvocab = {}\n",
    "with open('common-vocab-index.pickle', 'rb') as f:\n",
    "    commonvocab = pickle.load(f)\n",
    "list(commonvocab.keys())[7260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.52451825e-01, -3.24319627e-02, -2.77466886e-02,  8.13460443e-02,\n",
       "        5.92073572e-02,  5.29265206e-03,  2.82709899e-02, -4.10130175e-02,\n",
       "       -3.72760571e-02, -2.26741472e-02, -6.70740656e-02,  2.33680557e-02,\n",
       "        1.48349215e-01,  5.86283656e-02, -4.34921838e-02,  1.52196014e-02,\n",
       "       -1.02812216e-02,  4.02334360e-02, -9.89008183e-03,  1.49252177e-02,\n",
       "       -4.88889459e-02,  5.11624657e-04, -8.23032937e-02, -7.03315042e-02,\n",
       "        8.34581908e-03, -5.70643335e-02,  2.80378371e-02, -3.16122645e-02,\n",
       "        1.04138866e-01, -2.80117488e-02, -9.80843702e-03,  4.50507456e-02,\n",
       "       -7.38177866e-02,  3.43025327e-02, -2.65286786e-02, -1.89344390e-02,\n",
       "       -2.94337994e-02,  1.53375506e-02, -3.19133665e-02, -5.45609911e-02,\n",
       "       -8.41236687e-02, -1.08542055e-01,  3.99398344e-02, -5.94535111e-02,\n",
       "       -3.84440583e-03,  7.81781597e-03, -2.59605284e-02,  5.84319028e-02,\n",
       "       -5.11038999e-02,  8.68011562e-02, -4.92141797e-02,  4.78485163e-02,\n",
       "       -2.52334661e-02, -6.67002311e-03, -6.62776757e-02, -4.46273125e-03,\n",
       "       -3.38346384e-02,  3.85058666e-02,  6.45255393e-02, -9.09392607e-02,\n",
       "        2.83715349e-02,  1.89970364e-02, -5.68576526e-03,  4.95065818e-03,\n",
       "       -7.15155968e-02,  3.39469754e-02,  3.22410330e-02,  7.46055805e-02,\n",
       "       -1.41019033e-02,  2.34061473e-02,  2.14442603e-02,  8.59503990e-02,\n",
       "        3.09449950e-03, -7.68113547e-02, -7.17512696e-03,  6.68837157e-03,\n",
       "       -9.00907318e-02,  6.58395879e-02, -1.14580392e-02, -3.01373772e-02,\n",
       "       -5.61427545e-02,  9.98557417e-02,  1.18099539e-01,  4.54196625e-02,\n",
       "        8.06433931e-02, -6.12810525e-02,  3.08164148e-03,  3.76000560e-02,\n",
       "       -2.39306176e-02,  3.03012231e-02,  1.03845899e-01,  3.45654917e-03,\n",
       "       -5.25337470e-02,  2.98436238e-02,  8.36086730e-02, -7.44806752e-03,\n",
       "        2.19285940e-02, -5.12573319e-02, -8.58627563e-02, -5.06520222e-02,\n",
       "        1.42665441e-02,  8.65614136e-03,  8.43259901e-04, -7.17696435e-03,\n",
       "        8.78857981e-02,  2.62173977e-02,  5.33571853e-02,  4.27092010e-02,\n",
       "        1.39756186e-02,  4.20749662e-02,  1.02186703e-01,  2.19710019e-02,\n",
       "        5.63716414e-02, -1.09318056e-01, -2.79043599e-02,  1.79672389e-02,\n",
       "       -8.94226563e-02, -4.23706991e-02, -2.53629948e-02, -1.57547542e-02,\n",
       "        6.69242747e-02,  6.03234407e-02, -3.53487991e-03,  1.48466525e-02,\n",
       "        1.48408712e-02,  1.80870911e-02, -1.23043076e-01,  5.68771516e-02,\n",
       "        4.26184759e-02, -4.74683151e-02,  1.57955684e-02,  1.26995175e-01,\n",
       "        1.32591700e-02,  5.37612830e-02,  3.45795296e-02, -1.63176475e-03,\n",
       "       -1.17073415e-02,  1.01892059e-02,  7.91615019e-05,  1.05172160e-01,\n",
       "        8.23870067e-02,  5.61120174e-02,  1.10874915e-01, -1.75459929e-02,\n",
       "       -2.03678445e-02,  7.04389356e-02,  4.55084088e-02,  2.32712081e-02,\n",
       "       -9.26030533e-02,  9.21239234e-03,  2.88526427e-03,  5.49816080e-02,\n",
       "       -8.65953449e-02,  7.01677320e-02,  4.41867688e-03,  3.59279365e-02,\n",
       "        3.03037198e-02, -4.95937628e-02,  8.03863744e-02,  4.29379808e-02,\n",
       "       -1.42110471e-03,  2.76560314e-02,  2.51660910e-03,  1.68091245e-03,\n",
       "       -1.42216576e-02,  5.19800156e-02,  9.27382767e-02, -5.95537280e-02,\n",
       "        3.96096498e-02,  1.36475418e-01, -3.51683788e-02, -1.17309934e-03,\n",
       "        5.83148893e-02, -2.10503261e-02,  9.45794657e-02, -5.22788351e-02,\n",
       "        4.79208233e-02, -6.32945954e-03, -3.56129335e-03,  5.11599061e-02,\n",
       "       -7.63445861e-02, -1.54868427e-02,  8.68280576e-03, -8.74733213e-02,\n",
       "       -4.60272608e-02,  1.06753772e-03,  6.77046838e-02,  1.20952345e-02,\n",
       "       -1.14177404e-01, -6.11888435e-03, -8.43051897e-02, -5.49683786e-02,\n",
       "        2.23917030e-02,  7.83887467e-02,  4.61566229e-03,  1.19629237e-02,\n",
       "       -5.66805727e-02,  7.14803128e-02,  1.43251082e-02,  2.72656448e-02,\n",
       "       -5.40326951e-02, -7.10195221e-02, -5.38807147e-02,  1.67222691e-02,\n",
       "        1.63156699e-02, -3.34409743e-02,  1.15943674e-02,  1.53666510e-02,\n",
       "        1.07298795e-01,  2.65505795e-02, -1.35976895e-02,  4.39638100e-02,\n",
       "        3.68993342e-02,  9.68147426e-02, -1.63721923e-03,  3.85915174e-02,\n",
       "        1.04477501e-01, -2.82699349e-02,  6.00588186e-02,  1.49529991e-01,\n",
       "       -4.50195680e-02, -9.00400865e-02, -6.56266339e-02,  3.71769194e-03,\n",
       "       -5.81391661e-02, -4.73882496e-02, -4.23678787e-02,  6.97507326e-03,\n",
       "        7.69338641e-03,  1.38721495e-01,  1.05814149e-02, -2.31976694e-02,\n",
       "        8.11252381e-03,  1.20348510e-02, -2.21034415e-03,  1.55699154e-01,\n",
       "        3.05286980e-02, -4.12644295e-02, -2.45074304e-02,  2.01962809e-04,\n",
       "        5.01468489e-02, -1.01074970e-02, -1.24224641e-02, -2.21164296e-02,\n",
       "        1.41710970e-02, -1.79255642e-02,  6.30468564e-02,  5.09703693e-02,\n",
       "        2.28346951e-02,  5.74159861e-02, -5.25579210e-03, -5.49377906e-03,\n",
       "       -2.27478549e-02, -4.87030972e-02,  1.10183353e-02, -3.68240176e-02,\n",
       "       -1.10661284e-02, -6.66947021e-03,  7.62858935e-02, -1.41953195e-01,\n",
       "        1.04177946e-01,  7.70557476e-02,  1.07678695e-02, -4.54733360e-02,\n",
       "       -4.41283658e-02, -9.39160630e-04, -1.84660604e-02, -8.61652156e-03,\n",
       "       -6.97221035e-02, -7.14056596e-02,  6.04808137e-03,  2.06188104e-02,\n",
       "        8.68855403e-02,  5.88278405e-02,  8.72509306e-02,  6.78016760e-02,\n",
       "       -7.56973535e-02,  9.09815537e-02, -2.35108685e-02, -1.16713094e-02,\n",
       "       -1.30031209e-01, -3.71655896e-02,  5.56506138e-03, -9.96056338e-02,\n",
       "        5.84969498e-02, -7.01482288e-02,  7.14851144e-02, -1.42874279e-01,\n",
       "        3.47542643e-02, -8.57149852e-02,  6.88138452e-02, -1.24364597e-01,\n",
       "        1.26951582e-01, -7.35075831e-02, -7.89028267e-02, -7.83455724e-02,\n",
       "       -2.63935977e-02, -2.28634966e-02, -1.24436567e-02,  9.33983756e-02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common word vectors\n",
    "commonvec = {}\n",
    "with open('common-vocab-vectors.pickle', 'rb') as f:\n",
    "    commonvec = pickle.load(f)\n",
    "commonvec['1990'][7260] #check if loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clusters\n",
    "clustsagg = {}\n",
    "with open('cluster-center-vectors.pickle', 'rb') as f:\n",
    "    clustsagg = pickle.load(f)\n",
    "# check size (100 clusters of 300 dim vectors per timestamp)\n",
    "clustsagg['1810'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "timestepSimilarities = {}\n",
    "for t in w_keys:\n",
    "    timestepSimilarities[t] = cosine_similarity(commonvec[t],clustsagg[t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7446, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestepSimilarities['1810'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for t in w_keys:\n",
    "    for w in timestepSimilarities[t]:\n",
    "        k=0\n",
    "        for i in w:\n",
    "            if(i != 0):\n",
    "                k=1\n",
    "        cnt += k\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5108.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt/20\n",
    "#so about 2/3rd of the word had some similarities to the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestepChanges = [] #row index is index of word, each column is the timestep difference\n",
    "\n",
    "for i in range(timestepSimilarities['1810'].shape[0]):\n",
    "    worddelta = []\n",
    "    t1 = timestepSimilarities['1810'][i]\n",
    "    for t in w_keys[1:]:\n",
    "        t2 = timestepSimilarities[t][i]\n",
    "        delta = t2-t1\n",
    "        worddelta.append(delta)\n",
    "        t1 = t2\n",
    "    timestepChanges.append(worddelta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timestepChanges[0]) # should be 19, since delta over 20 timesteps\n",
    "#'{:.2e}'.format(timestepSimilarities['1800'][0][35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 33, 35, 32, 99], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test before loop\n",
    "word =  timestepSimilarities['1810'][0]\n",
    "npword = word\n",
    "npword.shape\n",
    "clustindexes = np.argpartition(npword, -5)[-5:]\n",
    "clustindexes[np.argsort(npword[clustindexes])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7446"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closestClusters = []\n",
    "movementAltMethod = []\n",
    "topk = 5\n",
    "for i in range(len(timestepSimilarities['1810'])):\n",
    "    npword = timestepSimilarities['1800'][i]\n",
    "    clustindexes = np.argpartition(npword, -topk)[-topk:]\n",
    "    closestClusters.append(clustindexes[np.argsort(npword[clustindexes])])\n",
    "    movealtword = []\n",
    "    for t in range(len(timestepChanges[0])):\n",
    "        word_t = timestepSimilarities[w_keys[t]][i]\n",
    "        maxindex_t = np.argpartition(word_t, -topk)[-topk:]\n",
    "        diff = timestepChanges[i][t]\n",
    "        movealtword.append(sum(diff[maxindex_t])/len(diff[maxindex_t]))\n",
    "    movementAltMethod.append(movealtword)\n",
    "len(closestClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7446"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movementAltMethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(closestClusters[7445])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordMovements = [] #relative to most similar clusters\n",
    "for i in range(len(timestepChanges)):\n",
    "    clusts = closestClusters[i]\n",
    "    movement = timestepChanges[i]\n",
    "    avgmovementOverTime = []\n",
    "    for diff in movement:\n",
    "        avgmovement = sum(diff[clusts])/len(diff[clusts])\n",
    "        avgmovementOverTime.append(avgmovement)\n",
    "    wordMovements.append(avgmovementOverTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordMovements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7446"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxChangeMagnitude = []\n",
    "timestepOfChange = []\n",
    "def getMove(wordMovements):\n",
    "    for wordMove in wordMovements:\n",
    "        maximumChange = max(wordMove)\n",
    "        maxIndex = wordMove.index(maximumChange)\n",
    "        maxChangeMagnitude.append(maximumChange)\n",
    "        timestepOfChange.append(maxIndex)\n",
    "# getMove(wordMovements)\n",
    "getMove(movementAltMethod)\n",
    "len(timestepOfChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7446"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maxChangeMagnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60 # number of words for analysis\n",
    "offset = len(maxChangeMagnitude)-n #start looking at words from this index\n",
    "magnitudes = np.array(maxChangeMagnitude)\n",
    "nMostChangedWords = []\n",
    "if(offset!=0):\n",
    "    nMostChangedWords = np.argsort(magnitudes)[-n-offset:-offset][::-1]\n",
    "else:\n",
    "    nMostChangedWords = np.argsort(magnitudes)[-n:][::-1]\n",
    "nTopValues = [magnitudes[i] for i in nMostChangedWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nTopValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "topWords = []\n",
    "timeStep = []\n",
    "vocab = list(commonvocab.keys())\n",
    "for i in nMostChangedWords:\n",
    "    topWords.append(vocab[i])\n",
    "    t = timestepOfChange[i]\n",
    "    timeStep.append(w_keys[t] + ' to ' + w_keys[t+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angeles              from 1800 to 1810 with score 0.0\n",
      "drink                from 1800 to 1810 with score 0.0\n",
      "hardest              from 1800 to 1810 with score 0.0\n",
      "radio                from 1800 to 1810 with score 0.0\n",
      "rubbed               from 1800 to 1810 with score 0.0\n",
      "goin                 from 1800 to 1810 with score 0.0\n",
      "outskirts            from 1800 to 1810 with score 0.0\n",
      "avenue               from 1800 to 1810 with score 0.0\n",
      "eat                  from 1800 to 1810 with score 0.0\n",
      "mess                 from 1800 to 1810 with score 0.0\n",
      "nothin               from 1800 to 1810 with score 0.0\n",
      "safe                 from 1800 to 1810 with score 0.0\n",
      "tucked               from 1800 to 1810 with score 0.0\n",
      "kid                  from 1800 to 1810 with score 0.0\n",
      "smiling              from 1800 to 1810 with score 0.0\n",
      "expect               from 1800 to 1810 with score 0.0\n",
      "remembered           from 1800 to 1810 with score 0.0\n",
      "landing              from 1800 to 1810 with score 0.0\n",
      "uh                   from 1800 to 1810 with score 0.0\n",
      "midnight             from 1800 to 1810 with score 0.0\n",
      "mile                 from 1800 to 1810 with score 0.0\n",
      "village              from 1800 to 1810 with score 0.0\n",
      "goodbye              from 1800 to 1810 with score 0.0\n",
      "tenth                from 1800 to 1810 with score 0.0\n",
      "bother               from 1800 to 1810 with score 0.0\n",
      "movies               from 1800 to 1810 with score 0.0\n",
      "months               from 1800 to 1810 with score 0.0\n",
      "publication          from 1800 to 1810 with score 0.0\n",
      "asleep               from 1800 to 1810 with score 0.0\n",
      "dare                 from 1800 to 1810 with score 0.0\n",
      "pillow               from 1800 to 1810 with score 0.0\n",
      "lasted               from 1800 to 1810 with score 0.0\n",
      "guess                from 1800 to 1810 with score 0.0\n",
      "slapped              from 1800 to 1810 with score 0.0\n",
      "ahead                from 1800 to 1810 with score 0.0\n",
      "knows                from 1800 to 1810 with score 0.0\n",
      "begged               from 1800 to 1810 with score 0.0\n",
      "forget               from 1800 to 1810 with score 0.0\n",
      "horrified            from 1800 to 1810 with score 0.0\n",
      "devil                from 1800 to 1810 with score 0.0\n",
      "hallway              from 1800 to 1810 with score 0.0\n",
      "forgive              from 1800 to 1810 with score 0.0\n",
      "lap                  from 1800 to 1810 with score 0.0\n",
      "sleeping             from 1800 to 1810 with score 0.0\n",
      "spent                from 1800 to 1810 with score 0.0\n",
      "wants                from 1800 to 1810 with score 0.0\n",
      "space                from 1800 to 1810 with score 0.0\n",
      "manners              from 1800 to 1810 with score 0.0\n",
      "traveled             from 1800 to 1810 with score 0.0\n",
      "bet                  from 1800 to 1810 with score 0.0\n",
      "breakfast            from 1800 to 1810 with score 0.0\n",
      "toronto              from 1800 to 1810 with score 0.0\n",
      "lets                 from 1800 to 1810 with score 0.0\n",
      "pick                 from 1800 to 1810 with score 0.0\n",
      "lookin               from 1800 to 1810 with score 0.0\n",
      "hang                 from 1800 to 1810 with score 0.0\n",
      "ll                   from 1800 to 1810 with score 0.0\n",
      "mama                 from 1800 to 1810 with score 0.0\n",
      "everyone             from 1800 to 1810 with score 0.0\n",
      "damn                 from 1800 to 1810 with score 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(topWords)):\n",
    "    print(\"{:20s} from {} with score {}\".format(topWords[i],timeStep[i], nTopValues[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1830 to 1840',\n",
       " '1830 to 1840',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1820 to 1830',\n",
       " '1830 to 1840']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
